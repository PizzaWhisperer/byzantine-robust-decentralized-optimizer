
=== Start adding workers ===
=> Add worker SGDMWorker(index=0, momentum=0.9)
=> Add worker SGDMWorker(index=1, momentum=0.9)
=> Add worker SGDMWorker(index=2, momentum=0.9)
=> Add worker SGDMWorker(index=3, momentum=0.9)
=> Add worker SGDMWorker(index=4, momentum=0.9)
=> Add worker ByzantineWorker(index=5)
=> Add worker ByzantineWorker(index=6)
=> Add worker ByzantineWorker(index=7)
=> Add worker ByzantineWorker(index=8)
=> Add worker ByzantineWorker(index=9)
=> Add worker ByzantineWorker(index=10)
=> Add worker ByzantineWorker(index=11)
=> Add worker ByzantineWorker(index=12)
=> Add worker ByzantineWorker(index=13)
=> Add worker ByzantineWorker(index=14)

=== Start adding graph ===
<__main__.MaliciousRing object at 0x7f3208193430>

Train epoch 1
[E 1B0  |    480/60000 (  1%) ] Loss: 2.3052 top1= 11.2500

=== Peeking data label distribution E1B0 ===
Worker 0 has targets: tensor([9, 0, 5, 4, 6], device='cuda:0')
Worker 1 has targets: tensor([3, 6, 4, 0, 8], device='cuda:0')
Worker 2 has targets: tensor([5, 8, 7, 0, 7], device='cuda:0')
Worker 3 has targets: tensor([4, 9, 4, 7, 7], device='cuda:0')
Worker 4 has targets: tensor([7, 9, 1, 0, 2], device='cuda:0')
Worker 5 has targets: tensor([4, 3, 8, 6, 8], device='cuda:0')
Worker 6 has targets: tensor([9, 1, 7, 7, 8], device='cuda:0')
Worker 7 has targets: tensor([6, 3, 3, 8, 5], device='cuda:0')
Worker 8 has targets: tensor([8, 2, 3, 9, 7], device='cuda:0')
Worker 9 has targets: tensor([8, 5, 5, 2, 1], device='cuda:0')
Worker 10 has targets: tensor([7, 0, 1, 1, 9], device='cuda:0')
Worker 11 has targets: tensor([4, 2, 6, 0, 3], device='cuda:0')
Worker 12 has targets: tensor([8, 1, 0, 7, 1], device='cuda:0')
Worker 13 has targets: tensor([9, 6, 1, 9, 2], device='cuda:0')
Worker 14 has targets: tensor([4, 5, 4, 2, 4], device='cuda:0')



=== Log mixing matrix @ E1B0 ===
[[0.556 0.111 0.    0.    0.111 0.111 0.    0.    0.    0.    0.111 0.
  0.    0.    0.   ]
 [0.111 0.556 0.111 0.    0.    0.    0.111 0.    0.    0.    0.    0.111
  0.    0.    0.   ]
 [0.    0.111 0.556 0.111 0.    0.    0.    0.111 0.    0.    0.    0.
  0.111 0.    0.   ]
 [0.    0.    0.111 0.556 0.111 0.    0.    0.    0.111 0.    0.    0.
  0.    0.111 0.   ]
 [0.111 0.    0.    0.111 0.556 0.    0.    0.    0.    0.111 0.    0.
  0.    0.    0.111]
 [0.111 0.    0.    0.    0.    0.889 0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.111 0.    0.    0.    0.    0.889 0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.111 0.    0.    0.    0.    0.889 0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.111 0.    0.    0.    0.    0.889 0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.111 0.    0.    0.    0.    0.889 0.    0.
  0.    0.    0.   ]
 [0.111 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.889 0.
  0.    0.    0.   ]
 [0.    0.111 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.889
  0.    0.    0.   ]
 [0.    0.    0.111 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.889 0.    0.   ]
 [0.    0.    0.    0.111 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.889 0.   ]
 [0.    0.    0.    0.    0.111 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.889]]


[E 1B10 |   5280/60000 (  9%) ] Loss: 1.9759 top1= 51.2500
[E 1B20 |  10080/60000 ( 17%) ] Loss: 0.9609 top1= 74.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.6088 top1= 80.6891

Train epoch 2
[E 2B0  |    480/60000 (  1%) ] Loss: 0.7792 top1= 79.3750
[E 2B10 |   5280/60000 (  9%) ] Loss: 0.6526 top1= 80.0000
[E 2B20 |  10080/60000 ( 17%) ] Loss: 0.5600 top1= 85.6250

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.4759 top1= 88.5817

Train epoch 3
[E 3B0  |    480/60000 (  1%) ] Loss: 0.5241 top1= 88.1250
[E 3B10 |   5280/60000 (  9%) ] Loss: 0.6223 top1= 79.3750
[E 3B20 |  10080/60000 ( 17%) ] Loss: 0.4877 top1= 89.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.4586 top1= 88.2612

Train epoch 4
[E 4B0  |    480/60000 (  1%) ] Loss: 0.5306 top1= 85.6250
[E 4B10 |   5280/60000 (  9%) ] Loss: 0.5412 top1= 85.0000
[E 4B20 |  10080/60000 ( 17%) ] Loss: 0.4982 top1= 86.2500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.4610 top1= 87.3698

Train epoch 5
[E 5B0  |    480/60000 (  1%) ] Loss: 0.5313 top1= 86.8750
[E 5B10 |   5280/60000 (  9%) ] Loss: 0.4993 top1= 85.6250
[E 5B20 |  10080/60000 ( 17%) ] Loss: 0.4605 top1= 86.8750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.5120 top1= 83.4034

Train epoch 6
[E 6B0  |    480/60000 (  1%) ] Loss: 0.6071 top1= 82.5000
[E 6B10 |   5280/60000 (  9%) ] Loss: 0.6476 top1= 81.2500
[E 6B20 |  10080/60000 ( 17%) ] Loss: 0.5026 top1= 85.6250

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.4314 top1= 87.8706

Train epoch 7
[E 7B0  |    480/60000 (  1%) ] Loss: 0.5068 top1= 83.7500
[E 7B10 |   5280/60000 (  9%) ] Loss: 0.5749 top1= 81.8750
[E 7B20 |  10080/60000 ( 17%) ] Loss: 0.4139 top1= 88.1250

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.4515 top1= 87.1494

Train epoch 8
[E 8B0  |    480/60000 (  1%) ] Loss: 0.5150 top1= 87.5000
[E 8B10 |   5280/60000 (  9%) ] Loss: 0.6008 top1= 81.2500
[E 8B20 |  10080/60000 ( 17%) ] Loss: 0.4261 top1= 87.5000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.4079 top1= 88.6118

Train epoch 9
[E 9B0  |    480/60000 (  1%) ] Loss: 0.4598 top1= 86.8750
[E 9B10 |   5280/60000 (  9%) ] Loss: 0.5718 top1= 80.6250
[E 9B20 |  10080/60000 ( 17%) ] Loss: 0.4078 top1= 88.1250

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.4039 top1= 88.8021

Train epoch 10
[E10B0  |    480/60000 (  1%) ] Loss: 0.5120 top1= 85.0000
[E10B10 |   5280/60000 (  9%) ] Loss: 0.5322 top1= 83.7500
[E10B20 |  10080/60000 ( 17%) ] Loss: 0.4443 top1= 86.2500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.4006 top1= 89.4030

Train epoch 11
[E11B0  |    480/60000 (  1%) ] Loss: 0.4655 top1= 87.5000
[E11B10 |   5280/60000 (  9%) ] Loss: 0.5747 top1= 80.6250
[E11B20 |  10080/60000 ( 17%) ] Loss: 0.4088 top1= 87.5000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3915 top1= 88.7921

Train epoch 12
[E12B0  |    480/60000 (  1%) ] Loss: 0.4533 top1= 86.8750
[E12B10 |   5280/60000 (  9%) ] Loss: 0.5366 top1= 78.7500
[E12B20 |  10080/60000 ( 17%) ] Loss: 0.4886 top1= 85.6250

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.4058 top1= 89.1026

Train epoch 13
[E13B0  |    480/60000 (  1%) ] Loss: 0.4795 top1= 86.8750
[E13B10 |   5280/60000 (  9%) ] Loss: 0.5217 top1= 83.1250
[E13B20 |  10080/60000 ( 17%) ] Loss: 0.3829 top1= 90.0000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3827 top1= 89.7436

Train epoch 14
[E14B0  |    480/60000 (  1%) ] Loss: 0.4216 top1= 86.8750
[E14B10 |   5280/60000 (  9%) ] Loss: 0.5582 top1= 84.3750
[E14B20 |  10080/60000 ( 17%) ] Loss: 0.3861 top1= 88.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3468 top1= 90.7051

Train epoch 15
[E15B0  |    480/60000 (  1%) ] Loss: 0.3900 top1= 90.0000
[E15B10 |   5280/60000 (  9%) ] Loss: 0.4632 top1= 86.8750
[E15B20 |  10080/60000 ( 17%) ] Loss: 0.4248 top1= 86.8750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3765 top1= 89.6534

Train epoch 16
[E16B0  |    480/60000 (  1%) ] Loss: 0.4469 top1= 86.2500
[E16B10 |   5280/60000 (  9%) ] Loss: 0.4691 top1= 83.7500
[E16B20 |  10080/60000 ( 17%) ] Loss: 0.3873 top1= 90.0000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3949 top1= 89.1927

Train epoch 17
[E17B0  |    480/60000 (  1%) ] Loss: 0.3780 top1= 90.6250
[E17B10 |   5280/60000 (  9%) ] Loss: 0.4687 top1= 85.0000
[E17B20 |  10080/60000 ( 17%) ] Loss: 0.4204 top1= 86.8750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3735 top1= 89.9339

Train epoch 18
[E18B0  |    480/60000 (  1%) ] Loss: 0.4040 top1= 89.3750
[E18B10 |   5280/60000 (  9%) ] Loss: 0.3938 top1= 87.5000
[E18B20 |  10080/60000 ( 17%) ] Loss: 0.3764 top1= 88.1250

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3485 top1= 90.5048

Train epoch 19
[E19B0  |    480/60000 (  1%) ] Loss: 0.3916 top1= 87.5000
[E19B10 |   5280/60000 (  9%) ] Loss: 0.5546 top1= 82.5000
[E19B20 |  10080/60000 ( 17%) ] Loss: 0.3896 top1= 90.0000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3591 top1= 90.1743

Train epoch 20
[E20B0  |    480/60000 (  1%) ] Loss: 0.4365 top1= 88.7500
[E20B10 |   5280/60000 (  9%) ] Loss: 0.4429 top1= 86.8750
[E20B20 |  10080/60000 ( 17%) ] Loss: 0.3729 top1= 90.0000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3480 top1= 90.1943

Train epoch 21
[E21B0  |    480/60000 (  1%) ] Loss: 0.3520 top1= 90.0000
[E21B10 |   5280/60000 (  9%) ] Loss: 0.4089 top1= 86.2500
[E21B20 |  10080/60000 ( 17%) ] Loss: 0.3663 top1= 89.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3475 top1= 90.8554

Train epoch 22
[E22B0  |    480/60000 (  1%) ] Loss: 0.4187 top1= 88.1250
[E22B10 |   5280/60000 (  9%) ] Loss: 0.4283 top1= 86.2500
[E22B20 |  10080/60000 ( 17%) ] Loss: 0.3992 top1= 88.1250

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3550 top1= 90.2344

Train epoch 23
[E23B0  |    480/60000 (  1%) ] Loss: 0.3965 top1= 88.1250
[E23B10 |   5280/60000 (  9%) ] Loss: 0.3846 top1= 86.8750
[E23B20 |  10080/60000 ( 17%) ] Loss: 0.3340 top1= 92.5000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3658 top1= 89.9038

Train epoch 24
[E24B0  |    480/60000 (  1%) ] Loss: 0.3692 top1= 88.1250
[E24B10 |   5280/60000 (  9%) ] Loss: 0.3761 top1= 88.7500
[E24B20 |  10080/60000 ( 17%) ] Loss: 0.3368 top1= 88.1250

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3585 top1= 90.2444

Train epoch 25
[E25B0  |    480/60000 (  1%) ] Loss: 0.4171 top1= 87.5000
[E25B10 |   5280/60000 (  9%) ] Loss: 0.3937 top1= 86.2500
[E25B20 |  10080/60000 ( 17%) ] Loss: 0.4173 top1= 87.5000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3231 top1= 91.2760

Train epoch 26
[E26B0  |    480/60000 (  1%) ] Loss: 0.4061 top1= 87.5000
[E26B10 |   5280/60000 (  9%) ] Loss: 0.4582 top1= 85.0000
[E26B20 |  10080/60000 ( 17%) ] Loss: 0.3173 top1= 91.8750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3257 top1= 90.9655

Train epoch 27
[E27B0  |    480/60000 (  1%) ] Loss: 0.3769 top1= 88.7500
[E27B10 |   5280/60000 (  9%) ] Loss: 0.4201 top1= 85.6250
[E27B20 |  10080/60000 ( 17%) ] Loss: 0.3354 top1= 88.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3387 top1= 90.1342

Train epoch 28
[E28B0  |    480/60000 (  1%) ] Loss: 0.3823 top1= 87.5000
[E28B10 |   5280/60000 (  9%) ] Loss: 0.4284 top1= 88.7500
[E28B20 |  10080/60000 ( 17%) ] Loss: 0.3807 top1= 88.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3376 top1= 90.3446

Train epoch 29
[E29B0  |    480/60000 (  1%) ] Loss: 0.3202 top1= 90.0000
[E29B10 |   5280/60000 (  9%) ] Loss: 0.4693 top1= 84.3750
[E29B20 |  10080/60000 ( 17%) ] Loss: 0.3456 top1= 88.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3508 top1= 90.0040

Train epoch 30
[E30B0  |    480/60000 (  1%) ] Loss: 0.3511 top1= 90.6250
[E30B10 |   5280/60000 (  9%) ] Loss: 0.3258 top1= 89.3750
[E30B20 |  10080/60000 ( 17%) ] Loss: 0.3268 top1= 89.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3179 top1= 91.1859

