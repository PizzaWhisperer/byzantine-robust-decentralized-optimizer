
=== Start adding workers ===
=> Add worker SGDMWorker(index=0, momentum=0.9)
=> Add worker SGDMWorker(index=1, momentum=0.9)
=> Add worker SGDMWorker(index=2, momentum=0.9)
=> Add worker SGDMWorker(index=3, momentum=0.9)
=> Add worker SGDMWorker(index=4, momentum=0.9)
=> Add worker ByzantineWorker(index=5)
=> Add worker ByzantineWorker(index=6)
=> Add worker ByzantineWorker(index=7)
=> Add worker ByzantineWorker(index=8)
=> Add worker ByzantineWorker(index=9)
=> Add worker ByzantineWorker(index=10)
=> Add worker ByzantineWorker(index=11)
=> Add worker ByzantineWorker(index=12)
=> Add worker ByzantineWorker(index=13)
=> Add worker ByzantineWorker(index=14)

=== Start adding graph ===
<__main__.MaliciousRing object at 0x7f33dc9e1310>

Train epoch 1
[E 1B0  |    480/60000 (  1%) ] Loss: 2.3052 top1= 11.2500

=== Peeking data label distribution E1B0 ===
Worker 0 has targets: tensor([9, 0, 5, 4, 6], device='cuda:0')
Worker 1 has targets: tensor([3, 6, 4, 0, 8], device='cuda:0')
Worker 2 has targets: tensor([5, 8, 7, 0, 7], device='cuda:0')
Worker 3 has targets: tensor([4, 9, 4, 7, 7], device='cuda:0')
Worker 4 has targets: tensor([7, 9, 1, 0, 2], device='cuda:0')
Worker 5 has targets: tensor([4, 3, 8, 6, 8], device='cuda:0')
Worker 6 has targets: tensor([9, 1, 7, 7, 8], device='cuda:0')
Worker 7 has targets: tensor([6, 3, 3, 8, 5], device='cuda:0')
Worker 8 has targets: tensor([8, 2, 3, 9, 7], device='cuda:0')
Worker 9 has targets: tensor([8, 5, 5, 2, 1], device='cuda:0')
Worker 10 has targets: tensor([7, 0, 1, 1, 9], device='cuda:0')
Worker 11 has targets: tensor([4, 2, 6, 0, 3], device='cuda:0')
Worker 12 has targets: tensor([8, 1, 0, 7, 1], device='cuda:0')
Worker 13 has targets: tensor([9, 6, 1, 9, 2], device='cuda:0')
Worker 14 has targets: tensor([4, 5, 4, 2, 4], device='cuda:0')



=== Log mixing matrix @ E1B0 ===
[[0.556 0.111 0.    0.    0.111 0.111 0.    0.    0.    0.    0.111 0.
  0.    0.    0.   ]
 [0.111 0.556 0.111 0.    0.    0.    0.111 0.    0.    0.    0.    0.111
  0.    0.    0.   ]
 [0.    0.111 0.556 0.111 0.    0.    0.    0.111 0.    0.    0.    0.
  0.111 0.    0.   ]
 [0.    0.    0.111 0.556 0.111 0.    0.    0.    0.111 0.    0.    0.
  0.    0.111 0.   ]
 [0.111 0.    0.    0.111 0.556 0.    0.    0.    0.    0.111 0.    0.
  0.    0.    0.111]
 [0.111 0.    0.    0.    0.    0.889 0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.111 0.    0.    0.    0.    0.889 0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.111 0.    0.    0.    0.    0.889 0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.111 0.    0.    0.    0.    0.889 0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.111 0.    0.    0.    0.    0.889 0.    0.
  0.    0.    0.   ]
 [0.111 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.889 0.
  0.    0.    0.   ]
 [0.    0.111 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.889
  0.    0.    0.   ]
 [0.    0.    0.111 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.889 0.    0.   ]
 [0.    0.    0.    0.111 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.889 0.   ]
 [0.    0.    0.    0.    0.111 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.889]]


[E 1B10 |   5280/60000 (  9%) ] Loss: 2.3164 top1= 16.2500
[E 1B20 |  10080/60000 ( 17%) ] Loss: 1.5696 top1= 49.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.6529 top1= 77.8846

Train epoch 2
[E 2B0  |    480/60000 (  1%) ] Loss: 0.8988 top1= 71.2500
[E 2B10 |   5280/60000 (  9%) ] Loss: 0.8468 top1= 76.2500
[E 2B20 |  10080/60000 ( 17%) ] Loss: 0.6163 top1= 81.8750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.4295 top1= 86.9892

Train epoch 3
[E 3B0  |    480/60000 (  1%) ] Loss: 0.6390 top1= 83.1250
[E 3B10 |   5280/60000 (  9%) ] Loss: 0.4491 top1= 86.8750
[E 3B20 |  10080/60000 ( 17%) ] Loss: 0.6101 top1= 83.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3581 top1= 89.8137

Train epoch 4
[E 4B0  |    480/60000 (  1%) ] Loss: 0.4513 top1= 89.3750
[E 4B10 |   5280/60000 (  9%) ] Loss: 0.3933 top1= 88.1250
[E 4B20 |  10080/60000 ( 17%) ] Loss: 0.3382 top1= 92.5000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.4717 top1= 85.3065

Train epoch 5
[E 5B0  |    480/60000 (  1%) ] Loss: 0.4559 top1= 85.6250
[E 5B10 |   5280/60000 (  9%) ] Loss: 0.4431 top1= 88.1250
[E 5B20 |  10080/60000 ( 17%) ] Loss: 0.5809 top1= 83.1250

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3645 top1= 89.4531

Train epoch 6
[E 6B0  |    480/60000 (  1%) ] Loss: 0.4977 top1= 86.8750
[E 6B10 |   5280/60000 (  9%) ] Loss: 0.3236 top1= 92.5000
[E 6B20 |  10080/60000 ( 17%) ] Loss: 0.8751 top1= 71.2500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=1.4350 top1= 77.4139

Train epoch 7
[E 7B0  |    480/60000 (  1%) ] Loss: 1.5779 top1= 47.5000
[E 7B10 |   5280/60000 (  9%) ] Loss: 2.0071 top1= 58.1250
[E 7B20 |  10080/60000 ( 17%) ] Loss: 1.3480 top1= 67.5000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=1.1882 top1= 72.4459

Train epoch 8
[E 8B0  |    480/60000 (  1%) ] Loss: 1.6834 top1= 47.5000
[E 8B10 |   5280/60000 (  9%) ] Loss: 1.9534 top1= 32.5000
[E 8B20 |  10080/60000 ( 17%) ] Loss: 1.7168 top1= 50.0000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.7094 top1= 81.0397

Train epoch 9
[E 9B0  |    480/60000 (  1%) ] Loss: 1.3314 top1= 70.6250
[E 9B10 |   5280/60000 (  9%) ] Loss: 0.8170 top1= 81.2500
[E 9B20 |  10080/60000 ( 17%) ] Loss: 0.8423 top1= 79.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=1.3881 top1= 77.5641

Train epoch 10
[E10B0  |    480/60000 (  1%) ] Loss: 1.8870 top1= 77.5000
[E10B10 |   5280/60000 (  9%) ] Loss: 0.6691 top1= 85.6250
[E10B20 |  10080/60000 ( 17%) ] Loss: 0.2308 top1= 92.5000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.5100 top1= 87.6202

Train epoch 11
[E11B0  |    480/60000 (  1%) ] Loss: 0.4589 top1= 87.5000
[E11B10 |   5280/60000 (  9%) ] Loss: 1.0017 top1= 76.2500
[E11B20 |  10080/60000 ( 17%) ] Loss: 1.9855 top1= 31.8750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=2.3110 top1= 10.0962

Train epoch 12
[E12B0  |    480/60000 (  1%) ] Loss: 2.3822 top1= 20.6250
[E12B10 |   5280/60000 (  9%) ] Loss: 2.1740 top1= 13.1250
[E12B20 |  10080/60000 ( 17%) ] Loss: 1.8052 top1= 32.5000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=2.3111 top1= 10.0962

Train epoch 13
[E13B0  |    480/60000 (  1%) ] Loss: 2.2872 top1= 13.7500
[E13B10 |   5280/60000 (  9%) ] Loss: 2.2666 top1= 18.7500
[E13B20 |  10080/60000 ( 17%) ] Loss: 2.3802 top1= 20.6250

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=2.3116 top1= 10.0962

Train epoch 14
[E14B0  |    480/60000 (  1%) ] Loss: 2.0741 top1= 25.0000
[E14B10 |   5280/60000 (  9%) ] Loss: 2.2495 top1= 11.2500
[E14B20 |  10080/60000 ( 17%) ] Loss: 2.2326 top1= 17.5000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=2.2247 top1= 18.2091

Train epoch 15
[E15B0  |    480/60000 (  1%) ] Loss: 2.2792 top1= 15.6250
[E15B10 |   5280/60000 (  9%) ] Loss: 2.3691 top1= 13.1250
[E15B20 |  10080/60000 ( 17%) ] Loss: 2.4670 top1= 17.5000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=2.3088 top1= 10.0962

Train epoch 16
[E16B0  |    480/60000 (  1%) ] Loss: 2.3022 top1= 12.5000
[E16B10 |   5280/60000 (  9%) ] Loss: 2.3219 top1=  7.5000
[E16B20 |  10080/60000 ( 17%) ] Loss: 2.4184 top1= 10.0000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=2.3063 top1= 10.0962

Train epoch 17
[E17B0  |    480/60000 (  1%) ] Loss: 2.2637 top1= 12.5000
[E17B10 |   5280/60000 (  9%) ] Loss: 2.2982 top1=  7.5000
[E17B20 |  10080/60000 ( 17%) ] Loss: 2.3224 top1=  9.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=2.3061 top1= 10.0962

Train epoch 18
[E18B0  |    480/60000 (  1%) ] Loss: 2.2896 top1= 13.7500
[E18B10 |   5280/60000 (  9%) ] Loss: 2.3042 top1=  6.8750
[E18B20 |  10080/60000 ( 17%) ] Loss: 3.0465 top1= 11.8750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=2.3051 top1= 10.0962

Train epoch 19
[E19B0  |    480/60000 (  1%) ] Loss: 2.3095 top1= 11.8750
[E19B10 |   5280/60000 (  9%) ] Loss: 2.4900 top1=  7.5000
[E19B20 |  10080/60000 ( 17%) ] Loss: 2.3284 top1= 10.0000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=2.3039 top1= 11.3482

Train epoch 20
[E20B0  |    480/60000 (  1%) ] Loss: 2.3143 top1=  8.7500
[E20B10 |   5280/60000 (  9%) ] Loss: 2.3188 top1= 11.2500
[E20B20 |  10080/60000 ( 17%) ] Loss: 2.5104 top1= 11.8750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=2.3052 top1= 11.3482

Train epoch 21
[E21B0  |    480/60000 (  1%) ] Loss: 2.3099 top1=  8.7500
[E21B10 |   5280/60000 (  9%) ] Loss: 2.3352 top1= 10.6250
[E21B20 |  10080/60000 ( 17%) ] Loss: 2.3001 top1= 13.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=2.3050 top1= 11.3482

Train epoch 22
[E22B0  |    480/60000 (  1%) ] Loss: 2.3206 top1=  9.3750
[E22B10 |   5280/60000 (  9%) ] Loss: 2.3264 top1= 11.2500
[E22B20 |  10080/60000 ( 17%) ] Loss: 2.3104 top1= 13.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=2.3063 top1= 11.3482

Train epoch 23
[E23B0  |    480/60000 (  1%) ] Loss: 2.3455 top1=  9.3750
[E23B10 |   5280/60000 (  9%) ] Loss: 2.3266 top1= 11.8750
[E23B20 |  10080/60000 ( 17%) ] Loss: 2.3011 top1= 13.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=2.3059 top1= 11.3482

Train epoch 24
[E24B0  |    480/60000 (  1%) ] Loss: 2.3107 top1=  8.7500
[E24B10 |   5280/60000 (  9%) ] Loss: 2.3124 top1= 11.8750
[E24B20 |  10080/60000 ( 17%) ] Loss: 2.3073 top1= 13.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=2.3087 top1= 11.3482

Train epoch 25
[E25B0  |    480/60000 (  1%) ] Loss: 2.3240 top1=  8.7500
[E25B10 |   5280/60000 (  9%) ] Loss: 2.3168 top1= 11.8750
[E25B20 |  10080/60000 ( 17%) ] Loss: 2.3142 top1= 13.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=2.3097 top1= 11.3482

Train epoch 26
[E26B0  |    480/60000 (  1%) ] Loss: 2.3214 top1=  8.7500
[E26B10 |   5280/60000 (  9%) ] Loss: 2.3351 top1= 10.0000
[E26B20 |  10080/60000 ( 17%) ] Loss: 2.3085 top1= 15.0000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=2.5233 top1= 10.3065

Train epoch 27
[E27B0  |    480/60000 (  1%) ] Loss: 2.3430 top1=  8.7500
[E27B10 |   5280/60000 (  9%) ] Loss: 2.4391 top1= 13.7500
[E27B20 |  10080/60000 ( 17%) ] Loss: 2.3900 top1= 13.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=2.3151 top1= 11.3482

Train epoch 28
[E28B0  |    480/60000 (  1%) ] Loss: 2.3345 top1=  8.7500
[E28B10 |   5280/60000 (  9%) ] Loss: 2.4239 top1= 11.8750
[E28B20 |  10080/60000 ( 17%) ] Loss: 2.3249 top1= 13.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=13.4726 top1=  9.7456

Train epoch 29
[E29B0  |    480/60000 (  1%) ] Loss: 2.6384 top1=  6.2500
[E29B10 |   5280/60000 (  9%) ] Loss: 2.6361 top1= 11.8750
[E29B20 |  10080/60000 ( 17%) ] Loss: 2.3214 top1= 13.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=2.3115 top1= 11.3482

Train epoch 30
[E30B0  |    480/60000 (  1%) ] Loss: 2.3293 top1=  8.7500
[E30B10 |   5280/60000 (  9%) ] Loss: 2.3152 top1= 11.2500
[E30B20 |  10080/60000 ( 17%) ] Loss: 2.3159 top1= 13.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=5.0842 top1= 10.0962

