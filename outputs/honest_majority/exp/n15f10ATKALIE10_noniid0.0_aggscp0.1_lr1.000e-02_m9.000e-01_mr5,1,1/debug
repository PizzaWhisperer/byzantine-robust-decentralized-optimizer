
=== Start adding workers ===
=> Add worker SGDMWorker(index=0, momentum=0.9)
=> Add worker SGDMWorker(index=1, momentum=0.9)
=> Add worker SGDMWorker(index=2, momentum=0.9)
=> Add worker SGDMWorker(index=3, momentum=0.9)
=> Add worker SGDMWorker(index=4, momentum=0.9)
=> Add worker ByzantineWorker(index=5)
=> Add worker ByzantineWorker(index=6)
=> Add worker ByzantineWorker(index=7)
=> Add worker ByzantineWorker(index=8)
=> Add worker ByzantineWorker(index=9)
=> Add worker ByzantineWorker(index=10)
=> Add worker ByzantineWorker(index=11)
=> Add worker ByzantineWorker(index=12)
=> Add worker ByzantineWorker(index=13)
=> Add worker ByzantineWorker(index=14)

=== Start adding graph ===
<__main__.MaliciousRing object at 0x7fe06649e3d0>

Train epoch 1
[E 1B0  |    480/60000 (  1%) ] Loss: 2.3052 top1= 11.2500

=== Peeking data label distribution E1B0 ===
Worker 0 has targets: tensor([9, 0, 5, 4, 6], device='cuda:0')
Worker 1 has targets: tensor([3, 6, 4, 0, 8], device='cuda:0')
Worker 2 has targets: tensor([5, 8, 7, 0, 7], device='cuda:0')
Worker 3 has targets: tensor([4, 9, 4, 7, 7], device='cuda:0')
Worker 4 has targets: tensor([7, 9, 1, 0, 2], device='cuda:0')
Worker 5 has targets: tensor([4, 3, 8, 6, 8], device='cuda:0')
Worker 6 has targets: tensor([9, 1, 7, 7, 8], device='cuda:0')
Worker 7 has targets: tensor([6, 3, 3, 8, 5], device='cuda:0')
Worker 8 has targets: tensor([8, 2, 3, 9, 7], device='cuda:0')
Worker 9 has targets: tensor([8, 5, 5, 2, 1], device='cuda:0')
Worker 10 has targets: tensor([7, 0, 1, 1, 9], device='cuda:0')
Worker 11 has targets: tensor([4, 2, 6, 0, 3], device='cuda:0')
Worker 12 has targets: tensor([8, 1, 0, 7, 1], device='cuda:0')
Worker 13 has targets: tensor([9, 6, 1, 9, 2], device='cuda:0')
Worker 14 has targets: tensor([4, 5, 4, 2, 4], device='cuda:0')



=== Log mixing matrix @ E1B0 ===
[[0.556 0.111 0.    0.    0.111 0.111 0.    0.    0.    0.    0.111 0.
  0.    0.    0.   ]
 [0.111 0.556 0.111 0.    0.    0.    0.111 0.    0.    0.    0.    0.111
  0.    0.    0.   ]
 [0.    0.111 0.556 0.111 0.    0.    0.    0.111 0.    0.    0.    0.
  0.111 0.    0.   ]
 [0.    0.    0.111 0.556 0.111 0.    0.    0.    0.111 0.    0.    0.
  0.    0.111 0.   ]
 [0.111 0.    0.    0.111 0.556 0.    0.    0.    0.    0.111 0.    0.
  0.    0.    0.111]
 [0.111 0.    0.    0.    0.    0.889 0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.111 0.    0.    0.    0.    0.889 0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.111 0.    0.    0.    0.    0.889 0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.111 0.    0.    0.    0.    0.889 0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.111 0.    0.    0.    0.    0.889 0.    0.
  0.    0.    0.   ]
 [0.111 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.889 0.
  0.    0.    0.   ]
 [0.    0.111 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.889
  0.    0.    0.   ]
 [0.    0.    0.111 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.889 0.    0.   ]
 [0.    0.    0.    0.111 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.889 0.   ]
 [0.    0.    0.    0.    0.111 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.889]]


[E 1B10 |   5280/60000 (  9%) ] Loss: 2.0688 top1= 35.0000
[E 1B20 |  10080/60000 ( 17%) ] Loss: 1.2054 top1= 60.0000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.5499 top1= 82.0913

Train epoch 2
[E 2B0  |    480/60000 (  1%) ] Loss: 0.8722 top1= 70.6250
[E 2B10 |   5280/60000 (  9%) ] Loss: 0.7294 top1= 75.6250
[E 2B20 |  10080/60000 ( 17%) ] Loss: 0.5211 top1= 86.2500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3814 top1= 89.0325

Train epoch 3
[E 3B0  |    480/60000 (  1%) ] Loss: 0.3325 top1= 90.0000
[E 3B10 |   5280/60000 (  9%) ] Loss: 0.3751 top1= 87.5000
[E 3B20 |  10080/60000 ( 17%) ] Loss: 0.1959 top1= 94.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3284 top1= 90.6150

Train epoch 4
[E 4B0  |    480/60000 (  1%) ] Loss: 0.1029 top1= 96.2500
[E 4B10 |   5280/60000 (  9%) ] Loss: 0.1196 top1= 96.8750
[E 4B20 |  10080/60000 ( 17%) ] Loss: 0.2783 top1= 91.2500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3407 top1= 90.5349

Train epoch 5
[E 5B0  |    480/60000 (  1%) ] Loss: 0.1071 top1= 96.8750
[E 5B10 |   5280/60000 (  9%) ] Loss: 0.1045 top1= 97.5000
[E 5B20 |  10080/60000 ( 17%) ] Loss: 0.1137 top1= 97.5000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3182 top1= 91.1659

Train epoch 6
[E 6B0  |    480/60000 (  1%) ] Loss: 0.0628 top1= 99.3750
[E 6B10 |   5280/60000 (  9%) ] Loss: 0.0632 top1= 97.5000
[E 6B20 |  10080/60000 ( 17%) ] Loss: 0.1158 top1= 95.6250

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3332 top1= 91.6767

Train epoch 7
[E 7B0  |    480/60000 (  1%) ] Loss: 0.0876 top1= 98.1250
[E 7B10 |   5280/60000 (  9%) ] Loss: 0.0754 top1= 96.8750
[E 7B20 |  10080/60000 ( 17%) ] Loss: 0.0902 top1= 96.8750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2925 top1= 92.4479

Train epoch 8
[E 8B0  |    480/60000 (  1%) ] Loss: 0.0958 top1= 96.8750
[E 8B10 |   5280/60000 (  9%) ] Loss: 0.0788 top1= 98.1250
[E 8B20 |  10080/60000 ( 17%) ] Loss: 0.0440 top1= 98.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3026 top1= 92.7784

Train epoch 9
[E 9B0  |    480/60000 (  1%) ] Loss: 0.1579 top1= 98.1250
[E 9B10 |   5280/60000 (  9%) ] Loss: 0.0624 top1= 96.8750
[E 9B20 |  10080/60000 ( 17%) ] Loss: 0.0325 top1=100.0000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2978 top1= 92.7384

Train epoch 10
[E10B0  |    480/60000 (  1%) ] Loss: 0.1132 top1= 95.6250
[E10B10 |   5280/60000 (  9%) ] Loss: 0.0850 top1= 98.7500
[E10B20 |  10080/60000 ( 17%) ] Loss: 0.1077 top1= 97.5000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2888 top1= 92.9788

Train epoch 11
[E11B0  |    480/60000 (  1%) ] Loss: 0.1066 top1= 96.2500
[E11B10 |   5280/60000 (  9%) ] Loss: 0.1246 top1= 97.5000
[E11B20 |  10080/60000 ( 17%) ] Loss: 0.0473 top1=100.0000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3086 top1= 93.0288

Train epoch 12
[E12B0  |    480/60000 (  1%) ] Loss: 0.0948 top1= 95.6250
[E12B10 |   5280/60000 (  9%) ] Loss: 0.1423 top1= 96.2500
[E12B20 |  10080/60000 ( 17%) ] Loss: 0.1268 top1= 93.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2860 top1= 93.2792

Train epoch 13
[E13B0  |    480/60000 (  1%) ] Loss: 0.1541 top1= 95.6250
[E13B10 |   5280/60000 (  9%) ] Loss: 0.0506 top1= 98.1250
[E13B20 |  10080/60000 ( 17%) ] Loss: 0.2257 top1= 95.6250

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2640 top1= 93.3393

Train epoch 14
[E14B0  |    480/60000 (  1%) ] Loss: 0.2730 top1= 94.3750
[E14B10 |   5280/60000 (  9%) ] Loss: 0.0707 top1= 96.8750
[E14B20 |  10080/60000 ( 17%) ] Loss: 0.0181 top1=100.0000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3613 top1= 93.4696

Train epoch 15
[E15B0  |    480/60000 (  1%) ] Loss: 0.3150 top1= 95.6250
[E15B10 |   5280/60000 (  9%) ] Loss: 0.1417 top1= 96.2500
[E15B20 |  10080/60000 ( 17%) ] Loss: 0.1599 top1= 96.2500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3047 top1= 93.5397

Train epoch 16
[E16B0  |    480/60000 (  1%) ] Loss: 0.1744 top1= 97.5000
[E16B10 |   5280/60000 (  9%) ] Loss: 0.0637 top1= 97.5000
[E16B20 |  10080/60000 ( 17%) ] Loss: 0.0622 top1= 98.1250

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2981 top1= 93.6999

Train epoch 17
[E17B0  |    480/60000 (  1%) ] Loss: 0.0631 top1= 96.8750
[E17B10 |   5280/60000 (  9%) ] Loss: 0.0078 top1=100.0000
[E17B20 |  10080/60000 ( 17%) ] Loss: 0.0295 top1= 98.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3182 top1= 93.5597

Train epoch 18
[E18B0  |    480/60000 (  1%) ] Loss: 0.0646 top1= 98.7500
[E18B10 |   5280/60000 (  9%) ] Loss: 0.0135 top1= 99.3750
[E18B20 |  10080/60000 ( 17%) ] Loss: 0.0186 top1= 99.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2745 top1= 93.8802

Train epoch 19
[E19B0  |    480/60000 (  1%) ] Loss: 0.0319 top1= 99.3750
[E19B10 |   5280/60000 (  9%) ] Loss: 0.0120 top1= 99.3750
[E19B20 |  10080/60000 ( 17%) ] Loss: 0.0290 top1= 99.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2777 top1= 94.0004

Train epoch 20
[E20B0  |    480/60000 (  1%) ] Loss: 0.0324 top1= 99.3750
[E20B10 |   5280/60000 (  9%) ] Loss: 0.0049 top1=100.0000
[E20B20 |  10080/60000 ( 17%) ] Loss: 0.0337 top1= 99.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3108 top1= 94.0605

Train epoch 21
[E21B0  |    480/60000 (  1%) ] Loss: 0.0134 top1= 99.3750
[E21B10 |   5280/60000 (  9%) ] Loss: 0.0495 top1= 98.1250
[E21B20 |  10080/60000 ( 17%) ] Loss: 0.0029 top1=100.0000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2821 top1= 94.1306

Train epoch 22
[E22B0  |    480/60000 (  1%) ] Loss: 0.0221 top1= 99.3750
[E22B10 |   5280/60000 (  9%) ] Loss: 0.0109 top1= 99.3750
[E22B20 |  10080/60000 ( 17%) ] Loss: 0.0229 top1= 99.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2318 top1= 94.4010

Train epoch 23
[E23B0  |    480/60000 (  1%) ] Loss: 0.0987 top1= 98.7500
[E23B10 |   5280/60000 (  9%) ] Loss: 0.0338 top1= 98.7500
[E23B20 |  10080/60000 ( 17%) ] Loss: 0.0340 top1= 99.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2429 top1= 94.4111

Train epoch 24
[E24B0  |    480/60000 (  1%) ] Loss: 0.0155 top1=100.0000
[E24B10 |   5280/60000 (  9%) ] Loss: 0.1268 top1= 98.7500
[E24B20 |  10080/60000 ( 17%) ] Loss: 0.0050 top1=100.0000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3222 top1= 94.0605

Train epoch 25
[E25B0  |    480/60000 (  1%) ] Loss: 0.0585 top1= 98.1250
[E25B10 |   5280/60000 (  9%) ] Loss: 0.0945 top1= 96.8750
[E25B20 |  10080/60000 ( 17%) ] Loss: 0.3099 top1= 98.1250

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3533 top1= 93.9704

Train epoch 26
[E26B0  |    480/60000 (  1%) ] Loss: 0.2450 top1= 96.8750
[E26B10 |   5280/60000 (  9%) ] Loss: 0.1991 top1= 96.8750
[E26B20 |  10080/60000 ( 17%) ] Loss: 0.0587 top1= 98.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3203 top1= 94.2508

Train epoch 27
[E27B0  |    480/60000 (  1%) ] Loss: 0.0167 top1= 99.3750
[E27B10 |   5280/60000 (  9%) ] Loss: 0.0885 top1= 97.5000
[E27B20 |  10080/60000 ( 17%) ] Loss: 0.0422 top1= 98.1250

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2815 top1= 94.5413

Train epoch 28
[E28B0  |    480/60000 (  1%) ] Loss: 0.0107 top1= 99.3750
[E28B10 |   5280/60000 (  9%) ] Loss: 0.0038 top1=100.0000
[E28B20 |  10080/60000 ( 17%) ] Loss: 0.0457 top1= 99.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2726 top1= 94.6514

Train epoch 29
[E29B0  |    480/60000 (  1%) ] Loss: 0.0082 top1=100.0000
[E29B10 |   5280/60000 (  9%) ] Loss: 0.0196 top1= 99.3750
[E29B20 |  10080/60000 ( 17%) ] Loss: 0.0065 top1=100.0000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2962 top1= 94.6314

Train epoch 30
[E30B0  |    480/60000 (  1%) ] Loss: 0.0027 top1=100.0000
[E30B10 |   5280/60000 (  9%) ] Loss: 0.0014 top1=100.0000
[E30B20 |  10080/60000 ( 17%) ] Loss: 0.0026 top1=100.0000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2735 top1= 94.6314

