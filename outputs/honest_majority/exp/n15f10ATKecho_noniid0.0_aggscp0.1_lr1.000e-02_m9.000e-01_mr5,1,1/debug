
=== Start adding workers ===
=> Add worker SGDMWorker(index=0, momentum=0.9)
=> Add worker SGDMWorker(index=1, momentum=0.9)
=> Add worker SGDMWorker(index=2, momentum=0.9)
=> Add worker SGDMWorker(index=3, momentum=0.9)
=> Add worker SGDMWorker(index=4, momentum=0.9)
=> Add worker ByzantineWorker(index=5)
=> Add worker ByzantineWorker(index=6)
=> Add worker ByzantineWorker(index=7)
=> Add worker ByzantineWorker(index=8)
=> Add worker ByzantineWorker(index=9)
=> Add worker ByzantineWorker(index=10)
=> Add worker ByzantineWorker(index=11)
=> Add worker ByzantineWorker(index=12)
=> Add worker ByzantineWorker(index=13)
=> Add worker ByzantineWorker(index=14)

=== Start adding graph ===
<__main__.MaliciousRing object at 0x7ff60a445430>

Train epoch 1
[E 1B0  |    480/60000 (  1%) ] Loss: 2.3052 top1= 11.2500

=== Peeking data label distribution E1B0 ===
Worker 0 has targets: tensor([9, 0, 5, 4, 6], device='cuda:0')
Worker 1 has targets: tensor([3, 6, 4, 0, 8], device='cuda:0')
Worker 2 has targets: tensor([5, 8, 7, 0, 7], device='cuda:0')
Worker 3 has targets: tensor([4, 9, 4, 7, 7], device='cuda:0')
Worker 4 has targets: tensor([7, 9, 1, 0, 2], device='cuda:0')
Worker 5 has targets: tensor([4, 3, 8, 6, 8], device='cuda:0')
Worker 6 has targets: tensor([9, 1, 7, 7, 8], device='cuda:0')
Worker 7 has targets: tensor([6, 3, 3, 8, 5], device='cuda:0')
Worker 8 has targets: tensor([8, 2, 3, 9, 7], device='cuda:0')
Worker 9 has targets: tensor([8, 5, 5, 2, 1], device='cuda:0')
Worker 10 has targets: tensor([7, 0, 1, 1, 9], device='cuda:0')
Worker 11 has targets: tensor([4, 2, 6, 0, 3], device='cuda:0')
Worker 12 has targets: tensor([8, 1, 0, 7, 1], device='cuda:0')
Worker 13 has targets: tensor([9, 6, 1, 9, 2], device='cuda:0')
Worker 14 has targets: tensor([4, 5, 4, 2, 4], device='cuda:0')



=== Log mixing matrix @ E1B0 ===
[[0.556 0.111 0.    0.    0.111 0.111 0.    0.    0.    0.    0.111 0.
  0.    0.    0.   ]
 [0.111 0.556 0.111 0.    0.    0.    0.111 0.    0.    0.    0.    0.111
  0.    0.    0.   ]
 [0.    0.111 0.556 0.111 0.    0.    0.    0.111 0.    0.    0.    0.
  0.111 0.    0.   ]
 [0.    0.    0.111 0.556 0.111 0.    0.    0.    0.111 0.    0.    0.
  0.    0.111 0.   ]
 [0.111 0.    0.    0.111 0.556 0.    0.    0.    0.    0.111 0.    0.
  0.    0.    0.111]
 [0.111 0.    0.    0.    0.    0.889 0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.111 0.    0.    0.    0.    0.889 0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.111 0.    0.    0.    0.    0.889 0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.111 0.    0.    0.    0.    0.889 0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.111 0.    0.    0.    0.    0.889 0.    0.
  0.    0.    0.   ]
 [0.111 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.889 0.
  0.    0.    0.   ]
 [0.    0.111 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.889
  0.    0.    0.   ]
 [0.    0.    0.111 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.889 0.    0.   ]
 [0.    0.    0.    0.111 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.889 0.   ]
 [0.    0.    0.    0.    0.111 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.889]]


[E 1B10 |   5280/60000 (  9%) ] Loss: 1.9424 top1= 37.5000
[E 1B20 |  10080/60000 ( 17%) ] Loss: 0.9665 top1= 67.5000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.5194 top1= 82.2115

Train epoch 2
[E 2B0  |    480/60000 (  1%) ] Loss: 0.7915 top1= 71.8750
[E 2B10 |   5280/60000 (  9%) ] Loss: 0.6739 top1= 76.8750
[E 2B20 |  10080/60000 ( 17%) ] Loss: 0.3651 top1= 89.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3502 top1= 89.5232

Train epoch 3
[E 3B0  |    480/60000 (  1%) ] Loss: 0.2363 top1= 93.1250
[E 3B10 |   5280/60000 (  9%) ] Loss: 0.3077 top1= 88.1250
[E 3B20 |  10080/60000 ( 17%) ] Loss: 0.1283 top1= 93.1250

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3095 top1= 90.9155

Train epoch 4
[E 4B0  |    480/60000 (  1%) ] Loss: 0.0533 top1= 98.7500
[E 4B10 |   5280/60000 (  9%) ] Loss: 0.0735 top1= 97.5000
[E 4B20 |  10080/60000 ( 17%) ] Loss: 0.0796 top1= 97.5000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3399 top1= 91.2760

Train epoch 5
[E 5B0  |    480/60000 (  1%) ] Loss: 0.0920 top1= 98.7500
[E 5B10 |   5280/60000 (  9%) ] Loss: 0.0542 top1= 98.7500
[E 5B20 |  10080/60000 ( 17%) ] Loss: 0.0062 top1=100.0000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3742 top1= 92.1074

Train epoch 6
[E 6B0  |    480/60000 (  1%) ] Loss: 0.0277 top1= 98.7500
[E 6B10 |   5280/60000 (  9%) ] Loss: 0.0667 top1= 98.1250
[E 6B20 |  10080/60000 ( 17%) ] Loss: 0.0298 top1= 98.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.4009 top1= 92.3377

Train epoch 7
[E 7B0  |    480/60000 (  1%) ] Loss: 0.0265 top1= 98.7500
[E 7B10 |   5280/60000 (  9%) ] Loss: 0.0225 top1= 99.3750
[E 7B20 |  10080/60000 ( 17%) ] Loss: 0.0280 top1= 98.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.4394 top1= 92.4279

Train epoch 8
[E 8B0  |    480/60000 (  1%) ] Loss: 0.0100 top1= 99.3750
[E 8B10 |   5280/60000 (  9%) ] Loss: 0.0058 top1=100.0000
[E 8B20 |  10080/60000 ( 17%) ] Loss: 0.0019 top1=100.0000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.4858 top1= 92.4980

Train epoch 9
[E 9B0  |    480/60000 (  1%) ] Loss: 0.0023 top1=100.0000
[E 9B10 |   5280/60000 (  9%) ] Loss: 0.0092 top1=100.0000
[E 9B20 |  10080/60000 ( 17%) ] Loss: 0.0202 top1= 98.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.5619 top1= 92.6282

Train epoch 10
[E10B0  |    480/60000 (  1%) ] Loss: 0.1159 top1= 97.5000
[E10B10 |   5280/60000 (  9%) ] Loss: 0.0094 top1= 99.3750
[E10B20 |  10080/60000 ( 17%) ] Loss: 0.0799 top1= 97.5000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.5308 top1= 92.8686

Train epoch 11
[E11B0  |    480/60000 (  1%) ] Loss: 0.1113 top1= 98.7500
[E11B10 |   5280/60000 (  9%) ] Loss: 0.1444 top1= 98.1250
[E11B20 |  10080/60000 ( 17%) ] Loss: 0.1556 top1= 98.1250

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.5914 top1= 92.6482

Train epoch 12
[E12B0  |    480/60000 (  1%) ] Loss: 0.3073 top1= 96.2500
[E12B10 |   5280/60000 (  9%) ] Loss: 0.3147 top1= 94.3750
[E12B20 |  10080/60000 ( 17%) ] Loss: 0.4316 top1= 91.8750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.4823 top1= 93.4796

Train epoch 13
[E13B0  |    480/60000 (  1%) ] Loss: 0.3714 top1= 93.1250
[E13B10 |   5280/60000 (  9%) ] Loss: 0.7402 top1= 92.5000
[E13B20 |  10080/60000 ( 17%) ] Loss: 0.3713 top1= 93.1250

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3546 top1= 94.0405

Train epoch 14
[E14B0  |    480/60000 (  1%) ] Loss: 0.4879 top1= 90.6250
[E14B10 |   5280/60000 (  9%) ] Loss: 0.2807 top1= 95.0000
[E14B20 |  10080/60000 ( 17%) ] Loss: 0.1344 top1= 95.6250

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3932 top1= 94.1506

Train epoch 15
[E15B0  |    480/60000 (  1%) ] Loss: 0.1015 top1= 97.5000
[E15B10 |   5280/60000 (  9%) ] Loss: 0.1696 top1= 96.2500
[E15B20 |  10080/60000 ( 17%) ] Loss: 0.0203 top1= 98.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.4095 top1= 94.5613

Train epoch 16
[E16B0  |    480/60000 (  1%) ] Loss: 0.0407 top1= 98.7500
[E16B10 |   5280/60000 (  9%) ] Loss: 0.0056 top1=100.0000
[E16B20 |  10080/60000 ( 17%) ] Loss: 0.2105 top1= 96.8750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.4424 top1= 94.5613

Train epoch 17
[E17B0  |    480/60000 (  1%) ] Loss: 0.0040 top1=100.0000
[E17B10 |   5280/60000 (  9%) ] Loss: 0.0536 top1= 98.1250
[E17B20 |  10080/60000 ( 17%) ] Loss: 0.0993 top1= 98.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.5124 top1= 94.4812

Train epoch 18
[E18B0  |    480/60000 (  1%) ] Loss: 0.0577 top1= 98.7500
[E18B10 |   5280/60000 (  9%) ] Loss: 0.0137 top1= 99.3750
[E18B20 |  10080/60000 ( 17%) ] Loss: 0.0774 top1= 98.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.5846 top1= 94.2808

Train epoch 19
[E19B0  |    480/60000 (  1%) ] Loss: 0.1520 top1= 98.7500
[E19B10 |   5280/60000 (  9%) ] Loss: 0.1238 top1= 98.7500
[E19B20 |  10080/60000 ( 17%) ] Loss: 0.0057 top1=100.0000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.5855 top1= 94.6314

Train epoch 20
[E20B0  |    480/60000 (  1%) ] Loss: 0.1487 top1= 97.5000
[E20B10 |   5280/60000 (  9%) ] Loss: 0.0126 top1= 98.7500
[E20B20 |  10080/60000 ( 17%) ] Loss: 0.1615 top1= 98.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.6168 top1= 94.9619

Train epoch 21
[E21B0  |    480/60000 (  1%) ] Loss: 0.0389 top1= 98.7500
[E21B10 |   5280/60000 (  9%) ] Loss: 0.0043 top1=100.0000
[E21B20 |  10080/60000 ( 17%) ] Loss: 0.0193 top1= 99.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.6651 top1= 94.6514

Train epoch 22
[E22B0  |    480/60000 (  1%) ] Loss: 0.0000 top1=100.0000
[E22B10 |   5280/60000 (  9%) ] Loss: 0.1158 top1= 99.3750
[E22B20 |  10080/60000 ( 17%) ] Loss: 0.0059 top1= 99.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.6716 top1= 95.0721

Train epoch 23
[E23B0  |    480/60000 (  1%) ] Loss: 0.1239 top1= 99.3750
[E23B10 |   5280/60000 (  9%) ] Loss: 0.0047 top1= 99.3750
[E23B20 |  10080/60000 ( 17%) ] Loss: 0.0000 top1=100.0000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.7819 top1= 94.7115

Train epoch 24
[E24B0  |    480/60000 (  1%) ] Loss: 0.0016 top1=100.0000
[E24B10 |   5280/60000 (  9%) ] Loss: 0.0004 top1=100.0000
[E24B20 |  10080/60000 ( 17%) ] Loss: 0.0000 top1=100.0000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.8000 top1= 95.1623

Train epoch 25
[E25B0  |    480/60000 (  1%) ] Loss: 0.0016 top1=100.0000
[E25B10 |   5280/60000 (  9%) ] Loss: 0.0000 top1=100.0000
[E25B20 |  10080/60000 ( 17%) ] Loss: 0.0125 top1= 99.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.8970 top1= 94.9720

Train epoch 26
[E26B0  |    480/60000 (  1%) ] Loss: 0.2288 top1= 98.7500
[E26B10 |   5280/60000 (  9%) ] Loss: 0.0393 top1= 99.3750
[E26B20 |  10080/60000 ( 17%) ] Loss: 0.3278 top1= 98.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.9933 top1= 95.1422

Train epoch 27
[E27B0  |    480/60000 (  1%) ] Loss: 0.5416 top1= 98.7500
[E27B10 |   5280/60000 (  9%) ] Loss: 0.3639 top1= 98.1250
[E27B20 |  10080/60000 ( 17%) ] Loss: 0.0538 top1= 99.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.9686 top1= 95.0621

Train epoch 28
[E28B0  |    480/60000 (  1%) ] Loss: 0.0007 top1=100.0000
[E28B10 |   5280/60000 (  9%) ] Loss: 0.0000 top1=100.0000
[E28B20 |  10080/60000 ( 17%) ] Loss: 0.0001 top1=100.0000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=1.1751 top1= 94.9018

Train epoch 29
[E29B0  |    480/60000 (  1%) ] Loss: 0.0000 top1=100.0000
[E29B10 |   5280/60000 (  9%) ] Loss: 0.0000 top1=100.0000
[E29B20 |  10080/60000 ( 17%) ] Loss: 0.3156 top1= 98.1250

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=1.2396 top1= 94.9319

Train epoch 30
[E30B0  |    480/60000 (  1%) ] Loss: 0.0000 top1=100.0000
[E30B10 |   5280/60000 (  9%) ] Loss: 0.0012 top1=100.0000
[E30B20 |  10080/60000 ( 17%) ] Loss: 0.5300 top1= 98.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=1.2563 top1= 95.2324

