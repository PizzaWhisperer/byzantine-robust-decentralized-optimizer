
=== Start adding workers ===
=> Add worker SGDMWorker(index=0, momentum=0.9)
=> Add worker SGDMWorker(index=1, momentum=0.9)
=> Add worker SGDMWorker(index=2, momentum=0.9)
=> Add worker SGDMWorker(index=3, momentum=0.9)
=> Add worker SGDMWorker(index=4, momentum=0.9)
=> Add worker ByzantineWorker(index=5)
=> Add worker ByzantineWorker(index=6)
=> Add worker ByzantineWorker(index=7)
=> Add worker ByzantineWorker(index=8)
=> Add worker ByzantineWorker(index=9)
=> Add worker ByzantineWorker(index=10)
=> Add worker ByzantineWorker(index=11)
=> Add worker ByzantineWorker(index=12)
=> Add worker ByzantineWorker(index=13)
=> Add worker ByzantineWorker(index=14)
=> Add worker ByzantineWorker(index=15)

=== Start adding graph ===
<__main__.MaliciousRing object at 0x7f5f7620a310>

Train epoch 1
[E 1B0  |    512/60000 (  1%) ] Loss: 2.3055 top1= 12.5000

=== Peeking data label distribution E1B0 ===
Worker 0 has targets: tensor([9, 6, 7, 7, 2], device='cuda:0')
Worker 1 has targets: tensor([3, 8, 4, 0, 8], device='cuda:0')
Worker 2 has targets: tensor([5, 9, 1, 6, 8], device='cuda:0')
Worker 3 has targets: tensor([4, 9, 8, 7, 5], device='cuda:0')
Worker 4 has targets: tensor([7, 3, 7, 8, 7], device='cuda:0')
Worker 5 has targets: tensor([4, 1, 3, 9, 1], device='cuda:0')
Worker 6 has targets: tensor([9, 3, 3, 2, 9], device='cuda:0')
Worker 7 has targets: tensor([6, 2, 5, 1, 3], device='cuda:0')
Worker 8 has targets: tensor([8, 5, 1, 0, 1], device='cuda:0')
Worker 9 has targets: tensor([8, 0, 6, 7, 2], device='cuda:0')
Worker 10 has targets: tensor([7, 2, 0, 9, 4], device='cuda:0')
Worker 11 has targets: tensor([4, 1, 1, 2, 8], device='cuda:0')
Worker 12 has targets: tensor([8, 6, 4, 6, 6], device='cuda:0')
Worker 13 has targets: tensor([9, 5, 4, 8, 5], device='cuda:0')
Worker 14 has targets: tensor([4, 5, 0, 7, 1], device='cuda:0')
Worker 15 has targets: tensor([0, 4, 0, 7, 6], device='cuda:0')



=== Log mixing matrix @ E1B0 ===
[[0.545 0.091 0.    0.    0.091 0.091 0.    0.    0.    0.    0.091 0.
  0.    0.    0.    0.091]
 [0.091 0.582 0.109 0.    0.    0.    0.109 0.    0.    0.    0.    0.109
  0.    0.    0.    0.   ]
 [0.    0.109 0.564 0.109 0.    0.    0.    0.109 0.    0.    0.    0.
  0.109 0.    0.    0.   ]
 [0.    0.    0.109 0.564 0.109 0.    0.    0.    0.109 0.    0.    0.
  0.    0.109 0.    0.   ]
 [0.091 0.    0.    0.109 0.582 0.    0.    0.    0.    0.109 0.    0.
  0.    0.    0.109 0.   ]
 [0.091 0.    0.    0.    0.    0.909 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.   ]
 [0.    0.109 0.    0.    0.    0.    0.891 0.    0.    0.    0.    0.
  0.    0.    0.    0.   ]
 [0.    0.    0.109 0.    0.    0.    0.    0.891 0.    0.    0.    0.
  0.    0.    0.    0.   ]
 [0.    0.    0.    0.109 0.    0.    0.    0.    0.891 0.    0.    0.
  0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.109 0.    0.    0.    0.    0.891 0.    0.
  0.    0.    0.    0.   ]
 [0.091 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.909 0.
  0.    0.    0.    0.   ]
 [0.    0.109 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.891
  0.    0.    0.    0.   ]
 [0.    0.    0.109 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.891 0.    0.    0.   ]
 [0.    0.    0.    0.109 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.891 0.    0.   ]
 [0.    0.    0.    0.    0.109 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.891 0.   ]
 [0.091 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.909]]


[E 1B10 |   5632/60000 (  9%) ] Loss: 1.3604 top1= 55.0000
[E 1B20 |  10752/60000 ( 18%) ] Loss: 0.6721 top1= 76.8750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.4440 top1= 88.0008

Train epoch 2
[E 2B0  |    512/60000 (  1%) ] Loss: 0.6729 top1= 77.5000
[E 2B10 |   5632/60000 (  9%) ] Loss: 0.4738 top1= 89.3750
[E 2B20 |  10752/60000 ( 18%) ] Loss: 0.2269 top1= 92.5000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2800 top1= 91.6667

Train epoch 3
[E 3B0  |    512/60000 (  1%) ] Loss: 0.2381 top1= 95.0000
[E 3B10 |   5632/60000 (  9%) ] Loss: 0.2041 top1= 95.0000
[E 3B20 |  10752/60000 ( 18%) ] Loss: 0.0761 top1= 96.8750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2393 top1= 93.1591

Train epoch 4
[E 4B0  |    512/60000 (  1%) ] Loss: 0.1127 top1= 97.5000
[E 4B10 |   5632/60000 (  9%) ] Loss: 0.0912 top1= 96.8750
[E 4B20 |  10752/60000 ( 18%) ] Loss: 0.0108 top1=100.0000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2433 top1= 93.2993

Train epoch 5
[E 5B0  |    512/60000 (  1%) ] Loss: 0.0668 top1= 98.1250
[E 5B10 |   5632/60000 (  9%) ] Loss: 0.0759 top1= 98.1250
[E 5B20 |  10752/60000 ( 18%) ] Loss: 0.0278 top1= 98.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2576 top1= 93.3594

Train epoch 6
[E 6B0  |    512/60000 (  1%) ] Loss: 0.0534 top1= 99.3750
[E 6B10 |   5632/60000 (  9%) ] Loss: 0.0494 top1= 98.7500
[E 6B20 |  10752/60000 ( 18%) ] Loss: 0.0194 top1= 99.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2248 top1= 93.7300

Train epoch 7
[E 7B0  |    512/60000 (  1%) ] Loss: 0.0415 top1= 99.3750
[E 7B10 |   5632/60000 (  9%) ] Loss: 0.0414 top1= 98.7500
[E 7B20 |  10752/60000 ( 18%) ] Loss: 0.0167 top1= 99.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2115 top1= 93.9103

Train epoch 8
[E 8B0  |    512/60000 (  1%) ] Loss: 0.0407 top1= 99.3750
[E 8B10 |   5632/60000 (  9%) ] Loss: 0.0412 top1= 98.7500
[E 8B20 |  10752/60000 ( 18%) ] Loss: 0.0199 top1= 98.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2114 top1= 93.8401

Train epoch 9
[E 9B0  |    512/60000 (  1%) ] Loss: 0.0395 top1= 99.3750
[E 9B10 |   5632/60000 (  9%) ] Loss: 0.0432 top1= 98.1250
[E 9B20 |  10752/60000 ( 18%) ] Loss: 0.0169 top1= 99.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2151 top1= 93.8702

Train epoch 10
[E10B0  |    512/60000 (  1%) ] Loss: 0.0388 top1= 99.3750
[E10B10 |   5632/60000 (  9%) ] Loss: 0.0482 top1= 98.1250
[E10B20 |  10752/60000 ( 18%) ] Loss: 0.0174 top1= 99.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2065 top1= 93.8902

Train epoch 11
[E11B0  |    512/60000 (  1%) ] Loss: 0.0380 top1= 99.3750
[E11B10 |   5632/60000 (  9%) ] Loss: 0.0478 top1= 98.1250
[E11B20 |  10752/60000 ( 18%) ] Loss: 0.0148 top1= 99.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2064 top1= 94.0905

Train epoch 12
[E12B0  |    512/60000 (  1%) ] Loss: 0.0380 top1= 99.3750
[E12B10 |   5632/60000 (  9%) ] Loss: 0.0406 top1= 98.1250
[E12B20 |  10752/60000 ( 18%) ] Loss: 0.0133 top1= 99.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2040 top1= 94.2107

Train epoch 13
[E13B0  |    512/60000 (  1%) ] Loss: 0.0393 top1= 99.3750
[E13B10 |   5632/60000 (  9%) ] Loss: 0.0415 top1= 98.1250
[E13B20 |  10752/60000 ( 18%) ] Loss: 0.0155 top1= 99.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2055 top1= 94.2208

Train epoch 14
[E14B0  |    512/60000 (  1%) ] Loss: 0.0376 top1= 99.3750
[E14B10 |   5632/60000 (  9%) ] Loss: 0.0523 top1= 98.1250
[E14B20 |  10752/60000 ( 18%) ] Loss: 0.0144 top1= 99.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2042 top1= 94.2408

Train epoch 15
[E15B0  |    512/60000 (  1%) ] Loss: 0.0381 top1= 99.3750
[E15B10 |   5632/60000 (  9%) ] Loss: 0.0470 top1= 98.1250
[E15B20 |  10752/60000 ( 18%) ] Loss: 0.0216 top1= 99.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2176 top1= 93.9303

Train epoch 16
[E16B0  |    512/60000 (  1%) ] Loss: 0.0365 top1= 99.3750
[E16B10 |   5632/60000 (  9%) ] Loss: 0.0471 top1= 98.1250
[E16B20 |  10752/60000 ( 18%) ] Loss: 0.0166 top1= 99.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2103 top1= 94.2508

Train epoch 17
[E17B0  |    512/60000 (  1%) ] Loss: 0.0371 top1= 99.3750
[E17B10 |   5632/60000 (  9%) ] Loss: 0.0443 top1= 98.1250
[E17B20 |  10752/60000 ( 18%) ] Loss: 0.0166 top1= 99.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2160 top1= 94.2408

Train epoch 18
[E18B0  |    512/60000 (  1%) ] Loss: 0.0385 top1= 99.3750
[E18B10 |   5632/60000 (  9%) ] Loss: 0.0488 top1= 98.1250
[E18B20 |  10752/60000 ( 18%) ] Loss: 0.0264 top1= 98.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2209 top1= 94.1707

Train epoch 19
[E19B0  |    512/60000 (  1%) ] Loss: 0.0368 top1= 99.3750
[E19B10 |   5632/60000 (  9%) ] Loss: 0.0489 top1= 98.1250
[E19B20 |  10752/60000 ( 18%) ] Loss: 0.0218 top1= 99.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2119 top1= 94.5312

Train epoch 20
[E20B0  |    512/60000 (  1%) ] Loss: 0.0854 top1= 98.1250
[E20B10 |   5632/60000 (  9%) ] Loss: 0.0486 top1= 98.1250
[E20B20 |  10752/60000 ( 18%) ] Loss: 0.0243 top1= 99.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2928 top1= 93.6198

Train epoch 21
[E21B0  |    512/60000 (  1%) ] Loss: 0.0745 top1= 98.1250
[E21B10 |   5632/60000 (  9%) ] Loss: 0.0508 top1= 98.1250
[E21B20 |  10752/60000 ( 18%) ] Loss: 0.0927 top1= 98.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3150 top1= 93.4896

Train epoch 22
[E22B0  |    512/60000 (  1%) ] Loss: 0.1963 top1= 96.8750
[E22B10 |   5632/60000 (  9%) ] Loss: 0.1842 top1= 95.6250
[E22B20 |  10752/60000 ( 18%) ] Loss: 0.0271 top1= 99.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.2995 top1= 93.8602

Train epoch 23
[E23B0  |    512/60000 (  1%) ] Loss: 0.0419 top1= 98.7500
[E23B10 |   5632/60000 (  9%) ] Loss: 0.0739 top1= 96.8750
[E23B20 |  10752/60000 ( 18%) ] Loss: 0.0563 top1= 98.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3227 top1= 93.7099

Train epoch 24
[E24B0  |    512/60000 (  1%) ] Loss: 0.0382 top1= 99.3750
[E24B10 |   5632/60000 (  9%) ] Loss: 0.0436 top1= 98.1250
[E24B20 |  10752/60000 ( 18%) ] Loss: 0.0596 top1= 97.5000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3308 top1= 94.4712

Train epoch 25
[E25B0  |    512/60000 (  1%) ] Loss: 0.0376 top1= 99.3750
[E25B10 |   5632/60000 (  9%) ] Loss: 0.0566 top1= 98.1250
[E25B20 |  10752/60000 ( 18%) ] Loss: 0.4175 top1= 96.8750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.4641 top1= 93.6098

Train epoch 26
[E26B0  |    512/60000 (  1%) ] Loss: 0.0677 top1= 98.7500
[E26B10 |   5632/60000 (  9%) ] Loss: 0.1246 top1= 96.8750
[E26B20 |  10752/60000 ( 18%) ] Loss: 0.0745 top1= 98.7500

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.4436 top1= 93.4696

Train epoch 27
[E27B0  |    512/60000 (  1%) ] Loss: 0.2884 top1= 98.7500
[E27B10 |   5632/60000 (  9%) ] Loss: 0.2732 top1= 96.8750
[E27B20 |  10752/60000 ( 18%) ] Loss: 0.1939 top1= 98.1250

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.4394 top1= 93.5397

Train epoch 28
[E28B0  |    512/60000 (  1%) ] Loss: 0.0571 top1= 98.7500
[E28B10 |   5632/60000 (  9%) ] Loss: 0.0755 top1= 97.5000
[E28B20 |  10752/60000 ( 18%) ] Loss: 0.0237 top1= 99.3750

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.5387 top1= 92.8886

Train epoch 29
[E29B0  |    512/60000 (  1%) ] Loss: 1.4849 top1= 97.5000
[E29B10 |   5632/60000 (  9%) ] Loss: 0.0431 top1= 98.1250
[E29B20 |  10752/60000 ( 18%) ] Loss: 0.0498 top1= 98.1250

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.4223 top1= 94.5413

Train epoch 30
[E30B0  |    512/60000 (  1%) ] Loss: 0.1600 top1= 98.1250
[E30B10 |   5632/60000 (  9%) ] Loss: 0.5271 top1= 95.6250
[E30B20 |  10752/60000 ( 18%) ] Loss: 0.2947 top1= 97.5000

=> Averaged model (Global Average Validation Accuracy) | Eval Loss=0.3287 top1= 93.6298

