
=== Start adding workers ===
=> Add worker SGDMWorker(index=0, momentum=0.9)
=> Add worker SGDMWorker(index=1, momentum=0.9)
=> Add worker SGDMWorker(index=2, momentum=0.9)
=> Add worker SGDMWorker(index=3, momentum=0.9)
=> Add worker SGDMWorker(index=4, momentum=0.9)
=> Add worker SGDMWorker(index=5, momentum=0.9)
=> Add worker SGDMWorker(index=6, momentum=0.9)
=> Add worker SGDMWorker(index=7, momentum=0.9)
=> Add worker SGDMWorker(index=8, momentum=0.9)
=> Add worker SGDMWorker(index=9, momentum=0.9)
=> Add worker SGDMWorker(index=10, momentum=0.9)
=> Add worker ByzantineWorker(index=11)

=== Start adding graph ===
TwoCliquesWithByzantine(m=5,b=1)

Train epoch 1
[E 1B0  |    384/60000 (  1%) ] Loss: 2.3142 top1=  7.6705

=== Peeking data label distribution E1B0 ===
Worker 0 has targets: tensor([0, 0, 0, 0, 0], device='cuda:0')
Worker 1 has targets: tensor([1, 1, 1, 0, 1], device='cuda:0')
Worker 2 has targets: tensor([1, 1, 2, 1, 1], device='cuda:0')
Worker 3 has targets: tensor([2, 2, 3, 2, 2], device='cuda:0')
Worker 4 has targets: tensor([3, 3, 3, 3, 3], device='cuda:0')
Worker 5 has targets: tensor([4, 4, 4, 4, 4], device='cuda:0')
Worker 6 has targets: tensor([5, 5, 5, 5, 5], device='cuda:0')
Worker 7 has targets: tensor([6, 6, 6, 5, 6], device='cuda:0')
Worker 8 has targets: tensor([6, 7, 7, 6, 6], device='cuda:0')
Worker 9 has targets: tensor([7, 7, 8, 7, 7], device='cuda:0')
Worker 10 has targets: tensor([8, 8, 9, 8, 8], device='cuda:0')
Worker 11 has targets: tensor([9, 9, 9, 9, 9], device='cuda:0')



=== Log global consensus distance @ E1B0 ===
consensus_distance=0.005



=== Log clique consensus distance @ E1B0 ===
clique1_consensus_distance=0.000
clique2_consensus_distance=0.000



=== Log mixing matrix @ E1B0 ===
[[0.167 0.167 0.167 0.167 0.167 0.    0.    0.    0.    0.    0.167 0.   ]
 [0.167 0.233 0.2   0.2   0.2   0.    0.    0.    0.    0.    0.    0.   ]
 [0.167 0.2   0.233 0.2   0.2   0.    0.    0.    0.    0.    0.    0.   ]
 [0.167 0.2   0.2   0.233 0.2   0.    0.    0.    0.    0.    0.    0.   ]
 [0.167 0.2   0.2   0.2   0.233 0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.233 0.2   0.2   0.2   0.167 0.    0.   ]
 [0.    0.    0.    0.    0.    0.2   0.233 0.2   0.2   0.167 0.    0.   ]
 [0.    0.    0.    0.    0.    0.2   0.2   0.233 0.2   0.167 0.    0.   ]
 [0.    0.    0.    0.    0.    0.2   0.2   0.2   0.233 0.167 0.    0.   ]
 [0.    0.    0.    0.    0.    0.167 0.167 0.167 0.167 0.167 0.167 0.   ]
 [0.167 0.    0.    0.    0.    0.    0.    0.    0.    0.167 0.417 0.25 ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.25  0.75 ]]


[E 1B10 |   4224/60000 (  7%) ] Loss: 2.0809 top1= 41.7614

=== Log global consensus distance @ E1B10 ===
consensus_distance=0.060



=== Log clique consensus distance @ E1B10 ===
clique1_consensus_distance=0.003
clique2_consensus_distance=0.034


[E 1B20 |   8064/60000 ( 13%) ] Loss: 1.7439 top1= 50.5682

=== Log global consensus distance @ E1B20 ===
consensus_distance=0.087



=== Log clique consensus distance @ E1B20 ===
clique1_consensus_distance=0.003
clique2_consensus_distance=0.143



=> Averaged model (Global Average Validation Accuracy) | Eval Loss=2.1438 top1= 31.9511


=> Averaged model (Clique1 Average Validation Accuracy) | Eval Loss=2.5565 top1= 37.9407


=> Averaged model (Clique2 Average Validation Accuracy) | Eval Loss=2.3744 top1= 33.7941

Train epoch 2
[E 2B0  |    384/60000 (  1%) ] Loss: 1.3609 top1= 67.8977

=== Log global consensus distance @ E2B0 ===
consensus_distance=0.118



=== Log clique consensus distance @ E2B0 ===
clique1_consensus_distance=0.004
clique2_consensus_distance=0.272


[E 2B10 |   4224/60000 (  7%) ] Loss: 1.0940 top1= 73.2955

=== Log global consensus distance @ E2B10 ===
consensus_distance=0.139



=== Log clique consensus distance @ E2B10 ===
clique1_consensus_distance=0.004
clique2_consensus_distance=0.366


[E 2B20 |   8064/60000 ( 13%) ] Loss: 0.8629 top1= 81.8182

=== Log global consensus distance @ E2B20 ===
consensus_distance=0.150



=== Log clique consensus distance @ E2B20 ===
clique1_consensus_distance=0.004
clique2_consensus_distance=0.414



=> Averaged model (Global Average Validation Accuracy) | Eval Loss=1.7576 top1= 57.6322


=> Averaged model (Clique1 Average Validation Accuracy) | Eval Loss=2.7228 top1= 39.2027


=> Averaged model (Clique2 Average Validation Accuracy) | Eval Loss=2.7212 top1= 35.1562

Train epoch 3
[E 3B0  |    384/60000 (  1%) ] Loss: 0.6405 top1= 89.2045

=== Log global consensus distance @ E3B0 ===
consensus_distance=0.155



=== Log clique consensus distance @ E3B0 ===
clique1_consensus_distance=0.004
clique2_consensus_distance=0.437


[E 3B10 |   4224/60000 (  7%) ] Loss: 0.5637 top1= 88.3523

=== Log global consensus distance @ E3B10 ===
consensus_distance=0.153



=== Log clique consensus distance @ E3B10 ===
clique1_consensus_distance=0.004
clique2_consensus_distance=0.429


[E 3B20 |   8064/60000 ( 13%) ] Loss: 0.5051 top1= 88.0682

=== Log global consensus distance @ E3B20 ===
consensus_distance=0.147



=== Log clique consensus distance @ E3B20 ===
clique1_consensus_distance=0.004
clique2_consensus_distance=0.404



=> Averaged model (Global Average Validation Accuracy) | Eval Loss=1.3974 top1= 69.6014


=> Averaged model (Clique1 Average Validation Accuracy) | Eval Loss=2.3395 top1= 39.6534


=> Averaged model (Clique2 Average Validation Accuracy) | Eval Loss=2.5460 top1= 37.3397

Train epoch 4
[E 4B0  |    384/60000 (  1%) ] Loss: 0.3800 top1= 92.0455

=== Log global consensus distance @ E4B0 ===
consensus_distance=0.141



=== Log clique consensus distance @ E4B0 ===
clique1_consensus_distance=0.004
clique2_consensus_distance=0.378


[E 4B10 |   4224/60000 (  7%) ] Loss: 0.4011 top1= 91.1932

=== Log global consensus distance @ E4B10 ===
consensus_distance=0.134



=== Log clique consensus distance @ E4B10 ===
clique1_consensus_distance=0.004
clique2_consensus_distance=0.345


[E 4B20 |   8064/60000 ( 13%) ] Loss: 0.3959 top1= 90.3409

=== Log global consensus distance @ E4B20 ===
consensus_distance=0.126



=== Log clique consensus distance @ E4B20 ===
clique1_consensus_distance=0.003
clique2_consensus_distance=0.313



=> Averaged model (Global Average Validation Accuracy) | Eval Loss=1.2281 top1= 72.4659


=> Averaged model (Clique1 Average Validation Accuracy) | Eval Loss=2.1071 top1= 40.1242


=> Averaged model (Clique2 Average Validation Accuracy) | Eval Loss=2.3716 top1= 39.5933

Train epoch 5
[E 5B0  |    384/60000 (  1%) ] Loss: 0.3122 top1= 92.0455

=== Log global consensus distance @ E5B0 ===
consensus_distance=0.121



=== Log clique consensus distance @ E5B0 ===
clique1_consensus_distance=0.003
clique2_consensus_distance=0.289


[E 5B10 |   4224/60000 (  7%) ] Loss: 0.3537 top1= 92.0455

=== Log global consensus distance @ E5B10 ===
consensus_distance=0.116



=== Log clique consensus distance @ E5B10 ===
clique1_consensus_distance=0.003
clique2_consensus_distance=0.268


[E 5B20 |   8064/60000 ( 13%) ] Loss: 0.3564 top1= 92.0455

=== Log global consensus distance @ E5B20 ===
consensus_distance=0.112



=== Log clique consensus distance @ E5B20 ===
clique1_consensus_distance=0.003
clique2_consensus_distance=0.250



=> Averaged model (Global Average Validation Accuracy) | Eval Loss=1.1605 top1= 73.4776


=> Averaged model (Clique1 Average Validation Accuracy) | Eval Loss=1.9822 top1= 41.6567

